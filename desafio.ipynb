{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos logs HTTP do Servidor da Nasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inicialização \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caminho do diretório do hdfs onde os arquivos de log estão armazenados\n",
    "path = \"/tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(line):\n",
    "    '''\n",
    "    line: linha do arquivo de log\n",
    "    retorna: retorna um spark Row contendo os campos host, date, url, code e bytes\n",
    "    '''\n",
    "    from pyspark.sql import Row\n",
    "    import re\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    #cria um dicionario\n",
    "    row = defaultdict() \n",
    "    \n",
    "    #busca pelo padrão regex na linha\n",
    "    host = re.search(r\"(?P<host>\\S+)\\s+\",line) \n",
    "    #Se o padrão for encontrado salva o resultado no dicionario, senão salva como Nulo \n",
    "    row['host'] = host.group('host') if host else None \n",
    "    \n",
    "    #busca pelo padrão regex na linha\n",
    "    date = re.search(r\".+\\[(?P<date>[\\w/]+)[\\w:]+\\s[+\\-]\\d{4}\\]+\",line)\n",
    "    #Se o padrão for encontrado salva o resultado no dicionario, senão salva como Nulo\n",
    "    row['date'] = date.group('date') if date else None\n",
    "    \n",
    "    #busca pelo padrão regex na linha\n",
    "    url = re.search(r\".+\\\"\\S+ (?P<url>\\S+)\\s+|\\\"\",line)\n",
    "    #Se o padrão for encontrado salva o resultado no dicionario, senão salva como Nulo\n",
    "    row['url'] = url.group('url') if url else None\n",
    "    \n",
    "    #busca pelo padrão regex na linha\n",
    "    code = re.search(r\".+\\\" (?P<code>\\d{3})+\",line)\n",
    "    #Se o padrão for encontrado salva o resultado no dicionario, senão salva como Nulo\n",
    "    row['code'] =  code.group('code') if code else None\n",
    "    \n",
    "    #busca pelo padrão regex na linha\n",
    "    byte = re.search(r\".+\\\" \\d{3} (?P<bytes>\\d+)\",line)\n",
    "    #Se o padrão for encontrado salva o resultado como inteiro no dicionario, senão salva como 0\n",
    "    row['byte'] = int(byte.group('bytes')) if byte else 0\n",
    "    return Row(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file1 = sc.textFile(path+\"NASA_access_log_Jul95\") # lê arquivo de log de Jul/95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log1= log_file1.map(parser).toDF() # aplica o paser em cada linha e cria um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----------+--------------------+-----------------------------------------------+\n",
      "|byte|code|date       |host                |url                                            |\n",
      "+----+----+-----------+--------------------+-----------------------------------------------+\n",
      "|6245|200 |01/Jul/1995|199.72.81.55        |/history/apollo/                               |\n",
      "|3985|200 |01/Jul/1995|unicomp6.unicomp.net|/shuttle/countdown/                            |\n",
      "|4085|200 |01/Jul/1995|199.120.110.21      |/shuttle/missions/sts-73/mission-sts-73.html   |\n",
      "|0   |304 |01/Jul/1995|burger.letters.com  |/shuttle/countdown/liftoff.html                |\n",
      "|4179|200 |01/Jul/1995|199.120.110.21      |/shuttle/missions/sts-73/sts-73-patch-small.gif|\n",
      "+----+----+-----------+--------------------+-----------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_log1.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lê arquivo de log de Jul/95, aplica o paser em cada linha e cria um dataframe \n",
    "df_log2 = sc.textFile(path+\"NASA_access_log_Aug95\").map(parser).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----------+-----------------+-----------------------------------------------+\n",
      "|byte|code|date       |host             |url                                            |\n",
      "+----+----+-----------+-----------------+-----------------------------------------------+\n",
      "|1839|200 |01/Aug/1995|in24.inetnebr.com|/shuttle/missions/sts-68/news/sts-68-mcc-05.txt|\n",
      "|0   |304 |01/Aug/1995|uplherc.upl.com  |/                                              |\n",
      "|0   |304 |01/Aug/1995|uplherc.upl.com  |/images/ksclogo-medium.gif                     |\n",
      "|0   |304 |01/Aug/1995|uplherc.upl.com  |/images/MOSAIC-logosmall.gif                   |\n",
      "|0   |304 |01/Aug/1995|uplherc.upl.com  |/images/USA-logosmall.gif                      |\n",
      "+----+----+-----------+-----------------+-----------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_log2.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Une os dois dataframes\n",
    "df_log = df_log1.union(df_log2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[byte: bigint, code: string, date: string, host: string, url: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matém o dataframe na memória\n",
    "df_log.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3461613"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.count()#total de linhas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos por coluna:\n",
      " byte=0\n",
      " code=1\n",
      " date=1\n",
      " host=1\n",
      " url=60\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de valores nulos por coluna:\")\n",
    "for col in df_log.columns:\n",
    "  print(\" {}={}\".format(col, df_log.filter(df_log[col].isNull() ).count()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+----+----+\n",
      "|byte|code|date|host| url|\n",
      "+----+----+----+----+----+\n",
      "|   0|null|null|null|null|\n",
      "+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#linhas em que a coluna host é nulo\n",
    "df_log.filter(df_log[\"host\"].isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado acima representa a última linha do arquivo NASA_access_log_Jul95, que contém apenas a string \"alyssa.p\", logo não representa o log de uma requisição HTTP. Desse modo, essa linha será removida do dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = df_log.filter(df_log[\"host\"].isNotNull()) #remove linha inválida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----------+---------------------------+----+\n",
      "|byte|code|date       |host                       |url |\n",
      "+----+----+-----------+---------------------------+----+\n",
      "|0   |302 |11/Jul/1995|jumbo.jet.uk               |null|\n",
      "|0   |302 |27/Jul/1995|drjo014a102.embratel.net.br|null|\n",
      "|0   |302 |14/Aug/1995|203.16.174.5               |null|\n",
      "|0   |302 |23/Aug/1995|mac391s.ksc.nasa.gov       |null|\n",
      "|0   |302 |23/Aug/1995|mac391s.ksc.nasa.gov       |null|\n",
      "+----+----+-----------+---------------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_log.filter(df_log[\"url\"].isNull()).show(5,truncate=False)#linhas em que a coluna url é nulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao testar as regex a serem utilizadas na função parser identifiquei que os valores nulos da colunas url são decorrentes de requisições que não apresentam url de fato como mostrado no exemplo abaixo,ou url que apresentam caracteres com problemas de codificação([Mojibake]([https://pt.wikipedia.org/wiki/Mojibake)).\n",
    "```\n",
    "\"GET  HTTP/1.0\"\n",
    "```\n",
    "Nesses casos optei por deixar os valores como nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número de hosts únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hosts únicos = 137978\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de hosts únicos = {}\".format(df_log.select(\"host\").distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O total de erros 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de erros 404 = 20901\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de erros 404 = {}\".format(df_log.filter(df_log['code']==\"404\").count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found = df_log.filter(df_log['code']==\"404\").cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Os 5 URLs que mais causaram erro 404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+-----+\n",
      "|url                                         |count|\n",
      "+--------------------------------------------+-----+\n",
      "|/pub/winvn/readme.txt                       |2004 |\n",
      "|/pub/winvn/release.txt                      |1732 |\n",
      "|/shuttle/missions/STS-69/mission-STS-69.html|682  |\n",
      "|/shuttle/missions/sts-68/ksc-upclose.gif    |426  |\n",
      "|/history/apollo/a-001/a-001-patch-small.gif |384  |\n",
      "+--------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "not_found.groupBy(\"url\").count().sort(desc(\"count\")).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantidade de erros 404 por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|       date|count|\n",
      "+-----------+-----+\n",
      "|02/Jul/1995|  291|\n",
      "|21/Aug/1995|  305|\n",
      "|06/Aug/1995|  373|\n",
      "|16/Jul/1995|  257|\n",
      "|07/Aug/1995|  537|\n",
      "|11/Aug/1995|  263|\n",
      "|27/Jul/1995|  336|\n",
      "|07/Jul/1995|  570|\n",
      "|17/Jul/1995|  406|\n",
      "|15/Jul/1995|  254|\n",
      "|18/Jul/1995|  465|\n",
      "|26/Jul/1995|  336|\n",
      "|03/Aug/1995|  304|\n",
      "|18/Aug/1995|  256|\n",
      "|17/Aug/1995|  271|\n",
      "|14/Aug/1995|  287|\n",
      "|10/Jul/1995|  398|\n",
      "|04/Jul/1995|  359|\n",
      "|20/Aug/1995|  312|\n",
      "|20/Jul/1995|  428|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "not_found.groupBy(\"date\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total de bytes retornados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de bytes retornados = 65524314915\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de bytes retornados = {}\".format(df_log.agg({\"byte\":\"sum\"}).collect()[0][0]) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}